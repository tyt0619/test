第一节：中文输入法技术基础
中文输入法技术
Windows输入法开发方法
Linux中文输入法框架

4中文输入法技术基础
•中文输入法技术
•Windows输入法框架
•Linux中文输入法主流框架

5怎样在计算机中输入中文？
•用键盘输入中文
–需要熟悉键盘布局
–掌握一定的输入方法：拼音，五笔等
•手写输入中文
–需要不大常用的输入设备：手写板或者支持手写输入的笔等；
–正确书写中文；
•语音输入
•扫描输入等

中文键盘输入法有什么特点？
•表意文字（如中，日，韩等）不能在键盘上找到相应的键，如果想在计算机中输入这些文字，就需要相应的输入法。
–输入法有很多种，如拼音，五笔等，但这些输入法的一个共同的特征是用户敲多个键来组成一个文字（或一组文字），统称为编码输入。
•在键盘输入法中，中文输入法有以下几种：
–拼音输入法：•学习门槛低，重码率高，输入效率低。•遇到不会读的字怎么办？
–五笔输入法•需要学习和熟悉的过程；•输入效率高；•遇到不会写的字怎么办？
–二笔输入法
–郑码输入法
–双拼输入法
6
怎样让中文输入更方便？
我们还有别的输入要求吗？

用户输入过程统共分几步？
7
1.应用程序（记事本，浏览器….）能接收输入信息
（键盘，语音…）；
2.将接收的信息通知给输入法进行分析处理；
3.输入法能根据信息给出适当的结果；
4.将输入结果反馈给应用程序，呈现给用户；
怎样开发一个输入法？

8中文输入法技术基础
•中文输入方法
•Windows输入法框架
•Linux中文输入法主流框架

Windows 输入法框架
•IMM-IME框架
–Windows95之前开发
–纯函数API
•TSF框架
–WindowsXp开始及以后
–基于COM技术

IMM-IME框架结构

IMM-IME的工作流程

TSF的构架
•TSF提供一个位于应用和输入法实现的间接层（一个Text service/TIP可以是一个输入法，或语音识别）。
•TSF是一个设备无关，语言中立
，可扩展的系统，同时给用户提供一致的输入体验；
•任何TSF-enabled应用程序都能从任何text service接受文字输入，而不用考虑Text source的具体细节。
•Text service也不用考虑各种不同应用的差别。
12

TSF应用场景

与应用程序的交互

与应用程序的交互

与应用程序的交互（3）

总结
•作出的重要改变：
–将多种输入模式统一到一个框架下。
–将多种语言统一到同一个框架下。
•在
Windows上实现一个输入法要考虑的问题：
–怎样在系统中注册自己的输入法；
–实现一个输入法时要响应哪些消息；
–怎样提供输入便利；
17

18中文输入法技术基础
•中文输入方法
•Windows输入法框架
•Linux中文输入法主流框架

Linux输入法框架
•XIM协议
–XIM(X Input Method)是X-Window
系统下的符合国际化标准的输入法协议。Fcitx输入法就是以此为基础开发的。
•Scim框架
–SCIM(Smart Common Input Method)
•Ibus框架
–Intelligent  Input  Bus因为它采用了总线（Bus）式的架构，所以命名为Bus。
19

Linux 下XIM协议
•XIM(X Input Method)简介–X-Window系统下的符合国际化标准的输入法协议，只要应用程序和系统都支持这种输入协议，应用程序就不必具体考虑在不同语言环境下的输入问题，系统可以根据相应的locale去寻找相应的输入法，从而达到国际化的要求。
•XIM体系结构：
–Client/Server模型
–Library
20

XIM体系结构-Client/Server模型
21
keyBoard
X-Server
IM Server
（input method）
应用程序
（XIM Client）
XIM Lib
1：按键

XIM协议输入流程-library
•所有的输入都由应用程序中的IM库来处理。事件处理在IM库中就被关闭了，所
以就不再需要一个独立的IM服务器。和Windows的IMM处理流程类似。
22
主要用于欧洲语
言等直接映射语
言的情况

XIM 架构分析
–一个X Sever 包括多个Locale 设置, XIM Sever 又必须依
赖于Locale设置。同时, 每个XIM Sever既可与一个Locale
相联, 也可同时与多个Locale相联接。而XIM Client 则通
过Locale与环境变量XMODIFIERS 来指定与某个XIM 
Sever 进行联接。

XIM框架总结
•早期的大部分中、日、韩输入法都是以此框架为基础；
•目前的Fcitx输入法也以此框架为基础；
•存在的问题：
–多种语言的输入法不能同时使用。
24

Scim框架
•开发目标
–大大简化输入法引擎的开发难度;
–用一套输入法框架同时支持多国语言的输入;
–降低输入法框架对平台和底层输入法协议的依赖,以便于将来移植到其他操作系统平台。
•采用的方式
–面向对象技术（c++）
•Scim具有如下特点：
–提供了一些非常好用的工具函数，可以大大加快开发进度
–提供了功能丰富的GUI panel
–提供了统一的配置框架
–很方便的集成现存的输入法
–不但支持传统的键盘输入法，也支持手写识别等新式输入法
•
25

Scim框架技术特点
•Scim是高度模块化的，每个模块都非常独立；
•采用动态加载机制，模块的调用者根本不关心采用
的哪种实现，接口与实现是分开的
•Scim采用了几种高级的技术：
–针对接口编程
–signal/slot机制
26

Scim体系结构
•模块动态加载机制
–Scim的整个设计干净利落，框架就是框架，其它任何附加的功能都是通过插件来实现的，在运行时才动态的加载进来。
–Scim实现了一个module类，对操作系统的底层函数进行了封装，同时提供面向对象的接口，使用更加方便。

Scim组成部件
•配置模块(Config)
•输入法前端模块(FrontEnd)
•输入法引擎模块(IMEngine)
•进程间通信模块(IPC)
•输入法Panel
•输入法Helper

Scim
•配置模块(Config)
–所有的配置信息由一个应用程序负责统一管理。只有它能够直接存取配置文件，其它应用程序，都需要通过向它发送请求来存取配置信息。
–Scim中定义ConfigBase接口•SimpleConfig，直接存取配置文件•SocketConfig，从输入法服务进程存取配置信息

Scim
•输入法前端模块(FrontEnd)
–指输入法服务进程中接收请求的模块。
–负责接收来自客户端应用程序的请求，把请求转发给具体的输入法引擎或者配置模块，最后把处理的结果返回给客户端应用程序。
–前端实现遵循FrontEndBase接口规范•SocketFrontEnd，定义了一套自己的通信协议，客户端应用程序必须遵循这个协议。•X11FrontEnd，基于XIM实现的，X Window提供的老式输入方式，似乎一般很少使用。

Scim
•进程间通信模块
–应用层协议封装在Transaction中，它负责把特定的请求或事件等打包成数据包，也负责从数据包中取出请求或事件等。至于数据的实际传输，由Socket实现。服务器端使用SocketServer，客户端使用SocketClient。Transaction使用的是Socket的抽象接口，并不关心是服务器端还是客户端。

Scim
•输入法Panel
–Panel不但给用户一种直观的反馈，如候选字，联想词组等，也提供了一些辅助功能，如中英文切换、全角半角切换，查看帮助信息等
–Scim实现了一个基于GTK的Panel，但它并不属于核心之列，它是一个完全独立的工具。

Scim
•输入法Helper
–一些新的输入法方式，如手写输入法等，当作传统的IMEngine来实现，比较麻烦也不太优雅。SCIM把这些输入法作为特殊处理，通过Helper集成进来。
–Scim提供了一个HelperAgent类，手写输入法通过它把手写结果提交给应用程序。HelperAgent实际是Panel的一个客户端，它与PanelAgent交互，但是它的功能很简单，而且与PanelClient功能并没有太多相似之处，所以作为一个单独的类来实现。

Scim
•输入法引擎模块(IMEngine)
–Scim中的输入法引擎的动态加载提供了两个默认的实现
–SocketInstance•它是一个输入法代理，一般来说，应用程序直接使用的就是它
–RawCodeInstance•按键原封不动的输出

Scim框架输入法引擎
•Scim框架默认情况下配置了英语键盘、智能拼音、五笔字型、自然码
、二笔、还有很多繁体输入法等
•项目scim-python：
–开发人员通过Python 语言来编写自己的输入法引擎。
–提供了包括拼音、五笔、二笔、郑码、仓颉等在内的多种中文输入法。
–具有快速输入特殊词语、临时的英文输入模式、以词选字、拼音纠错等功能；
–形码输入法则包含快速的输入速度、方便用户自定义词组、拼音反查等特点。

IBus
•Ibus（intelligent input bus）是下一代输入法框架（或者说“平台”）
–是Linux和类UNIX操作系统下的以GPL协议分发源代码的开源免费多语言输入法框架。
•IBUS采用总线（Bus）式的架构，所以命名为Bus。IBus支持多种输入法，如拼音输入法（包括全/简/双拼），并支持基于码表的输入法，如五
笔
、郑码
、二笔
和仓颉
等输入法，是多个流行的GNU/Linux
发行版（如Debian
，RedHat
等）的默认非英文输入法平台。
•Ibus项目现托管于Google Code -https://code.google.com/p/ibus/
，此项目包含了世界多数语言的文字输入需求，由世界多个国家开发者维护。
36

Ibus
•Ibus架构

Ibus
•Ibus是基于c/s的架构
–一个ibus-daemon的后台进程，管理所有的客户端
–所有的engines、panel、configmodules和IM(Input Method) clients都是ibus-daemon的客户端
–Ibus是基于dbusipc协议的

总结
•Fcitx、Scim、Ibus输入法框架比较
–发展顺序
•Fcitx→ Scim→ Ibus
–词库
•Ibus> Fcitx> Scim
–反应速度
•Fcitx> Ibus> Scim

总结
•三种输入法的使用界面

Scim-signal/slot机制
•多个不同的对象协作起来完成一项任务，是面向对象设计的特点
之一。消息在这些对象之间来回传递，特别是对于异步调用、事
件/状态触发等情况，底层模块需要调用上层模块中的函数。
•Scim里采用了signal/slot机制，上层向下层注册signal的处理器
(slot)。当某个signal触发时，下层模块回调signal的处理器(slot)。

第二节：fcitx输入法框架分析
Fcitx简介
Fcitx源码框架
Fcitx-table源码分析
Fcitx使用实例

Fcitx简介
Fcitx
（[ˈfaɪtɪks]，源自“Free Chinese Input Toy for 
X”，现英文全称“Flexible Input Method 
Framework”，中文名称为“小企鹅输入法”）是
一个在X Window
中使用的输入法框架。
Fcitx
是一个以GPL方式发布的、基于XIM的简体
中文输入法集合，包括五笔、五笔拼音、二笔、
仓颉、晚风、冰蟾全息、拼音(全拼和双拼)、区
位以及码表输入等，Linux
下的搜狗拼音也是以
fcitx
框架为基础。
可以在Linux
、FreeBSD中运行。

Fcitx简介
Fcitx支持的输入法引擎（12个）：
fcitx-anthy: 使用Anthy引擎的日文输入法
fcitx-chewing:libchewing的支持（新酷音输入法）
fcitx-cloudpinyin: 为所有拼音引擎提供云拼音支持
fcitx-googlepinyin: 移植自Android的Google拼音支持
fcitx-handwriting: Zinnia作为后端的手写支持
fcitx-keyboard: 采用系统键盘布局作为输入法，以及提供拼写检查
fcitx-libpinyin:libpinyin为后端的汉语拼音支持
fcitx-m17n: 使用m17n-db的多语言输入法
fcitx-mozc: 使用mozc引擎的日文输入法
fcitx-pinyin:汉语拼音支持
fcitx-sunpinyin:Sunpinyin为后端的汉语拼音支持
fcitx-table: 码表类输入法支持，如五笔、郑码等

Fcitx简介--Fcitx优点
响应速度快；
配置以及使用较为简单；
提供有码表的转换器等相应工具；
定义快捷键也较为简单；

Fcitx 键盘输入法
•fcitx简介
•Fcitx源码框架
•fcitx-table源码分析
•Fcitx的使用

Fcitx源码框架——编译Fcitx输入法
•源码安装
从http://download.fcitx-im.org/
下载相关输入法；
也可以通过sudoapt-get source fcitx下载源代码
在命令行下载相关组件sudoapt-get build-depfcitx（下载关联组件）
cd$SOURCEDIR
cmake./
Make
Sudomake install
开始进行Fcitx开发了！

Fcitx源码框架——fcitx源码结构
core：输入法主函数，错误异常处理
fronted：前端，gtk图形工具包，QT图形用户界面应用程序开发框架，XIM(X Input Method)标准协议
im：输入法引擎，包括pinyin（拼音），qw（区位），table（码表）
lib：输入法会使用到的函数库
module：模块，包括chttrans（简繁转换）、punc（标点转换）、quickphrase（快速组词）、vk（虚拟键盘）、x11（x相关功能）、autoeng（自动英文模式）等
ui：UI界面相关

Fcitx 架构
•根据这个过程fcitx处理键盘消息分为以下4阶段：
–PreInput
–DoInput
–PostInput
–Process Hotkey
•
10
具体到一个输入法引擎，那么会在DoInput阶段。
？
实现在“客户软件”上打字总共分几步？

Fcitx插件
•在Fcitx框架的基础上开发一个输入法，可以开发Fcitx-Addon（插件）
•Fcitx插件分为4类：
–Frontend：接收键盘事件，将其传递给fcitx；
–Input Method（im）：将输入转化为文本内容；
–Module：通过注册钩子可以做任何事；
–User Interface: 显示界面上需要显示的任何东西；
11

怎样在Fcitx上注册一个插件
•每个插件都需要一个configuration文件.格式如下：
12
对于不同类型的插件，要实现不同的处理接口

实现一个Frontend
•Frontend 插件是客户沟通的插件，处理客户端的输入，将字符串返回给客户。
•目前有13个函数要实现：
13

FrontEnd插件做了什么事？
•Frontend管理输入法的“环境数据”——context：
–每个输入法的客户至少有一个“环境数据”，是客户端的私有数据，每一个输入法的数据有唯一
标记——IC，CreateIC和DestroyIC就是这样处理这个标记，CheckIC保证IC不重复。
•“环境数据”保存着表明客户端输入法上下文激活与否的状态
–EnableIM和CloseIM是fcitx在输入法端想要激活或者关闭输入法上下文时使用；
•CommitString和ForwardKey向客户端传递字符串或者一些键盘消息.
•SetWindowOffset和GetWindowOffset会获取到客户端的鼠标信息.
•UpdatePreedit和UpdateClientSideU是I当UI元素比如预编辑字符串或者任
何ui元素发生更新的时候调用。
–这两个函数对带有capacity CAPACITY_PREEDIT 或CAPACITY_CLIENT_SIDE_UI尤
其有效. 只有当输入法上下文声明支持这个这两个函数才有效。14

module插件
•Module插件是通过钩子在输入法上做任何事；
•Module插件有2种：
–事件模型（Event module）
–非事件模型
15

module插件——事件模型
16
•事件模型使用fd来标记主循环里是
否有事件（event）发生。
•在从多fd中选择一个处理项，
module会触发ProcessEvent来完成
自己的工作；
•Module 需要更新和设置
FcitxInstance中rfds, wfds和maxfd
的值；
•在所有事件执行完后，参数值清零。

module插件——非事件模型
•非事件模型采用内嵌的钩子来介入键盘事件处理过程。
•目前，在处理键盘事件的过程中有效个钩子如下：
17

Module插件做了什么事
•Dbus
–桌面环境是KDE的情况下支持kimpanel插件；
–在没有X Server的情况下也能使用fcitx，如tty；
•X11
–X11模块处理X Server的相关功能，一般fcitx输入法都要使用这个模块；
•Cloudpinyin
–云拼音支持，对所有Fcitx输入法都有效；
18

user interface插件
•不同于Frontend, Input Method, 和Module, 只能有一个user interface运行；
•Fcitx已有的UI：
–fcitx-classic-ui•支持皮肤绘制，使用cairo, pango, 和xlib来绘制;
–fcitx-kimpanel-ui•采用通过Dbus的kimpanelprotocol，支持KDE或者gnome环境；•通过kdeplasma-addons-kimpanel提供的最基础的视觉效果；•通过kimtoy提供的皮肤支持;
–fcitx-light-ui•采用Xft和Xlib来绘制,用于支持老机器绘制库函数比较少的情况；
19

输入法引擎插件
•输入法引擎是输入法框架中最重要的插件：
–处理字符输入；
–更新预编辑字符串；
–设置候选字等；
•一个输入法引擎可以带不止一个输入法。
–比如fcitx-pinyin就带有一个拼音、注音、双拼等输入法。可以根据插件的注
册文件来确定。
20

Fcitx源码框架-总结
•Fcitx的一个实例输入法由多个模块组成，用户通过开发不同类型的插件
“定制”输入法：
–找到用户更想要的候选词？——定制更高级的输入法引擎
–拥有更漂亮的输入界面？——定制UI插件
–拥有更方面的功能？比如英文拼写校正，云输入。——开发功能模块
–采用哪种消息传递模式？——FrontEnd模块（目前，Fcitx拼音输入法也不仅
只基于XIM协议了。）
21

Fcitx 键盘输入法
•Fcitx简介
•Fcitx源码框架
•Fcitx-table源码分析
•Fcitx使用

Fcitx-table源码分析
•Fcitx-table输入法源代码内容：
23

Fcitx-table源码分析
•Data的内容：
24

注册输入法引擎——IM注册函数
25

注册输入法引擎——IM注册函数（2）
26

注册输入法引擎——IM注册函数（3）
Table类码表状态结构体

注册输入法引擎——IM注册函数（4）
28

注册输入法引擎——IM注册函数（5）
29
处理各个“子输入法”初始化配置

30注册各个输入法输入过程中回调函数：注册输入法引擎——IM注册函数（6）

输入法引擎处理流程
•根据输入情况
31
DoTableInput
IRV_TO_PROCESS
IRV_COMMIT_STRI
NG
IRV_DISPLAY_CAN
DWORDS
IRV_DO_NOTHING

Fcitx-Table实现细节
32

Fcitx 键盘输入法
•Fcitx简介
•Fcitx源码框架
•Fcitx-table源码分析
•Fcitx使用

Fcitx使用
•Fcitx配置参数
•Fcitx码表生成工具
34

Fcitx的config
文件
•Fcitx有两个prefix的目录
–PREFIX = /
usr/share/
fcitx
–USERPREFIX  = ~/.config/fcitx
•为了让fcitx的注册目录能找到这些输入法，这些输入法文件需要需要放置在合适的地点：
–PREFIX/
addon/
addon-name.conf
•如果一个插件有不同的参数需要注册，则需要一个config描述文件•PREFIX/configdesc/[addon-name].desc•对应的configure文件则是在目录USERPREFIX/conf
/, 名称是[addon-name].config
35

Fcitx使用
•常用热键
–打开/关闭输入法：左ctrl+空格
–快速中英文切换：左ctrl
–切换输入法：用左ctrl+左shift进行循环切换
–切换全/半角：左shift+空格
–候选字/词翻页：-=
–选择第二/ 三个候选词：左shift / 右shift

Fcitx使用
•拼音输入法
–支持全/简/双拼，双拼可自定义键盘方案
–支持常用字表
–特殊符号输入
–完善的预编辑
–支持以词定字
–模糊拼音

Fcitx使用
•Fcitx提供模糊拼音自定义

Fcitx使用
•常用字表
–设置常用字表的目的是为了方便录入某些常用字。
–在候选字中，处于该表中的字总是排在其它字的前面。
fcitx的默认常用字表是空的，可以用左ctrl+8/7来添加/
删除
常用字。例如，希望输入“d”时，“的”总放在第一个
，可以按一下操作：
•进入拼音状态，输入“d”，用翻页键-= 查找“的”字，直到它显示在候选字表中按ctrl+8，然后按“的”前面的数字序号即可。
–按上述操作可以为某个拼音编码设置多个常用字。

Fcitx使用
•双拼输入
–如果在配置文件中打开双拼选项，即可进行双拼输入。程序默认采用自然码的双拼方案，也可以自定义键盘方案。
–自定义时，将存放双拼方案的文件放在~/.config/fcitx下并重命名为sp.dat。程序源码包中的data
目录下有一个名为sp.dat的文件，该文件已经定义了一些双拼方案，修改“默认方案”即可以使用用户指定的方案。

Fcitx使用
•以词定字
–fcitx支持“以词定字”，以方便录入单个的字。按以词定字键（默认为‘[’/‘]’）选择该词组的第一个或第二个字。
–比如，在默认设置下，如果需要录入“霸”字，可以输入“bq”，让词组“霸气”显示在输入条上，然后按‘[’即可(如果按‘]’则是输出“气”字)。

Fcitx使用
•特殊符号输入
–为了录入特殊符号，必须将特殊符号按下列格式放在一个文件中：
<编码>   <符号>
–每个符号占一行。编码部分必须是英文小写字母，且经拼音解析后的长度不应超过10个汉字(如zzz是3个汉字长度，而zhangzhangzhang也是3个汉字长度
)
。
–编辑好特殊符号后，将其保存为文件pySym.mb，并放在~/.config/fcitx中，重新启动fcitx即可。

Fcitx使用
•五笔输入
–标准的五笔86输入功能
–自定义词组：在五笔状态下，按左ctrl+8添加新词；左ctrl+7删除词；左
ctrl+6
调整顺序
–快速拼音输入：按z键即可进入拼音录入状态，以方便不会打的字词，并提示
五笔编码(需要设置)

Fcitx使用
•在线造词方法(词组最长为10个汉字)：
–如果想删除词库中的词，先让该词显示中输入条上，按CTRL_7，并按提示操作即可；或是当程序提示有该词组时，按CTRL_DEL删除。
–如果想调整词库中词的顺序，按CTRL_6，并按提示操作即可。
•反查拼音
–如果不知道某个汉字的读音，可以先用码表输入法录入这个字，然后按反查拼音的热键（默认为CTRL_ALT_E），就可以查到该字的读音。

Fcitx使用
•Fcitx配置参数
•Fcitx码表生成工具
45

Fcitx使用
•码表输入法
–fcitx支持用户自定义码表输入法。
–系统的码表放置在usr/share/
fcitx/data/table/*.conf
–用户的码表和配置放置在~/.config/fcitx/table/*.conf

Fcitx使用
•制作拼音库
–在源码包的data
目录下包括了单字库和词组库，文件名为gbkpy.org和
pyPhrase.org。
–在tools目录下提供了一个制作拼音库的工具createPYMB。用法如下：
./createPYMB{拼音单字库} {拼音词组库}
–该工具将在当前目录下gbkpy.org和pyPhrase.org生成pybase.mb和
pyphrase.mb

Fcitx使用
•码表配置文件
–例子：五笔

Fcitx使用
•码表文件设置如下：
–[CodeTable]
–Name：名称，显示在程序主窗口的输入法名称。
–IconName：图标名称，皮肤中对应图标文件名。
–File：码表文件，该码表输入法的码表文件名，程序会先查找
~/.config/fcitx/table，然后在安装目录中找。
–AdjustOrder：调频，与拼音中的相应设置意义一样。
–Priority：优先级，码表输入法的优先级排序。
–UsePY：使用拼音，是否使用临时拼音输入。
–PYKey：拼音键，如果“拼音”选项打开，则以该字母起头的输入按全拼处
理。

Fcitx使用
•码表文件设置如下：
–AutoSend：自动上屏，当输入达到最大码表且只有一个候选词时是否自动上屏。
–NoneMatchAutoSend：空码自动上屏，空码时出空码前的内容。比如说abcd
是空码，而abc不是，那么打abcd时，就将abc的内容自动上屏，d留在提示行中
待处理。
–UseMatchingKey：使用模糊键，是否使用模糊(通配符)输入。
–MatchingKey：模糊键，模糊键(通配符)。
–AutoPhrase：自动词组，是否使用自动组词功能(后面有详细说明)。
–AutoPhraseLength：自动词组长度。

Fcitx使用
•码表文件设置如下：
–AutoPhrasePhrase：词组参与自动造词，指定录入的词组是否参与自动组词
。
–SaveAutoPhrase：保存自动词组，设定自动生成的词组被选择多少次后才被保存
。0表示不保存。
–ExactMatch：精确匹配，是否只在候选字表中显示精确匹配的结果。
–PromptTableCode：提示编码，是否提示录入字/
词的编码。
–Symbol：符号，设置该选项则开启特殊符号输入功能。
–SymbolFile：符号文件，特殊符号所在的文件。
–Enabled：是否启用该码表。

Fcitx使用
•码表输入法提供了两种在线造词方法(词组最长为10个汉字)：
–在中文输入方式下按CTRL_8，则利用将刚刚输入的内容造词，默认为最近输入法两个字，可以用左右方向键的增加或减少词组中的字
数。
–自动组词：将需要造的词按单字连续输入后，再按它的组词规则连续输入编码，程序会提示用户这个新词。如果此时按空格或它前面的序号则将这个新词输入到用户程序中，可以设置这个新词是否进入词库。如果不想录入该词，继续进行下一次输入即可(fcitx会记录
最近2048个输入的汉字)。

Fcitx使用
•制作码表
–data
目录下包括制造码表的工具：txt2mb和mb2txt。前者是将码表源文件转换为码表输入法所需的格式；后者是将码表文件转换为文本文件。码表源文件格式如右边所示：

Fcitx使用
•按上述格式制作好编码后，利用txt2mb将其转换为fcitx需要的格式：
–./txt2mb {源文件} {目标文件}
•然后将目标文件复制到~/.config/fcitx/table中，并在~/.config/fcitx/table/中建立对应conf
文件，然后在中文输入状态下按CTRL_5重新读入配置文件即可。
•如果希望将已经制作好的码表文件转换为文本文件，可以：
–./mb2txt {码表文件} [ > 文本文件]
•生成的文本文件将形如上述码表源文件的格式。

Fcitx使用
•中文标点
–fcitx的中文标点由一个文本文件设置，您可以根据自己的需要修改。该文件即<fcitx的安装目录>/share/fcitx/data/
punc.mb（或用户配置目
录下的punc.mb）。格式如下：
英文符号（对应）中文标点
–其中英文符号应该是类似“&*()”这样的符号，而中文标点最长为两
个汉字，最多有两组，中间由空格隔开。如：

第三节：中文分词
中文分词概念理解
中文分词常用算法
中文分词的难点及应用领域

中文分词
中文分词
分词就是将连续的字序列
按照一定的规范重新组
合成词序列的过程。

为什么面要中文分词？
•与英文为代表的拉丁语系语
言相比，英文以空格作为天
然的分隔符，而中文由于继
承自古代汉语的传统，词语
之间没有分隔。
•古代汉语中除了连绵词和人
名地名等，词通常就是单个
汉字，所以当时没有分词书
写的必要。而现代汉语中双
字或多字词居多，一个字不
再等同于一个词。

举例
知识就是力量
知识/就是/力量

中文的语义与字词的搭配相关
1、下雨天，留客天，留我？不留。
2、下雨天留客，天留，我不留。
3、下雨天，留客天，留我不？留。
4、下雨天留客，天留我不留。
5、下雨，天留客，天留，我不留。

定义
什么是分词？
分词就是利用计算机识别出文本中词汇的过程。比如
句子“内塔尼亚胡说的确实在理”

9第三节：中文分词
中文分词概念理解
中文分词常用算法
中文分词的难点及应用领域

分词算法分类
•基于字符串匹配的分词算法
•基于理解的分词算法
•基于统计的分词算法

字符串匹配分词（机械分词）
按照一定的策略
将待分析
的汉字串与一个“充分大
的”机器词典中的词条进
行配，若在词典中找到某
个字符串，则匹配成功（
识别出一个词）。常用的几种机械分词方法如下：
•1）正向最大匹配法由左到右的方向；
•2）逆向最大匹配法由右到左的方向；
•3）双向最大匹配法进行由左到右、由右到左两次扫描

12基本思想：
选取固定长个汉字的符号串作为最大符号串
，
把最大符号串与词典中的单词条目相匹配，如果
不能匹配，就去掉一个汉字继续匹配，直到在词
典中找到相应的单词为止。
匹配方向是从左向右，减字方向是从右向左。正向最大匹配算法

13算法流程：
第1步初始化字符串并设置最大符号串长度
P1为待分析字符串，初始值为用户输入的句子
P2为分词结果字符串，初始值为空
M为候选子串，初始值为空
第2步若P1不为空，从P1左边取出候选子串M
若P1为空，输出P2作为分词结果
第3步查词典，若M在词表中，将M加入到P2中，并将M从P1中去掉，
转第2步
若M不在词表中，将M的最右边一个字去掉，转第3步
算法举例正向最大匹配算法

•逆向最大匹配分词
–分词过程与FMM方法相同
–从句子(或文章)末尾开始处理，每次匹配不成功时去掉的是前面的一个汉字
–“市场/
中/
国有/
企业/
才能/
发展/ 
–实验表明：逆向最大匹配法比最大匹配法更有效，错误切分率为1／245
•双向匹配法
–比较FMM法与BMM法的切分结果，从而决定正确的切分
–可以识别出分词中的交叉歧义
–算法时间、空间复杂性较高
14

机械分词
•内塔尼亚胡
•胡说
•说
•的
•的确
•确实
•实在
•在理词典实例
内塔尼亚胡说的确实在理–FMM：内塔尼亚胡/说/的确/实在/理（错误）–BMM：内塔尼亚/胡说/的/确实/在理（错误）
词典从哪里来？

机械分词
优点
程序简单易行，开发周期短
没有任何复杂计算，分词速度快
不足
不能处理歧义
不能识别新词
分词精度不能满足实际的需要（规范文本80%，互联网文本在70%
左右）

理解分词方法
•这种分词方法是通过让计算机模拟人对句子的理解，达到识别词的效果。其基本思想就是在分词的同时进行句法、语义分析，利用句法信息和语义信息来处理歧义现象。
•它通常包括三个部分：
–分词子系统
–句法语义子系统
–总控部分
•特点
–在总控部分的协调下，分词子系统可以获得有关词、句子等的句法和语义信息来对分词歧义进行判断，即它模拟了人对句子的理解过程。
–这种分词方法需要使用大量的语言知识和信息。由于汉语语言知识的笼统、复杂性，难以将各种语言信息组织成机器可直接读取的形式，因此目前基于理解的分词系统还处在试验阶段。

统计分词
生成式统计分词
判别式统计分词

生成式分词
原理
首先建立学习样本的生成模型，再利用模型对预测结
果进行间接推理
两个假设前提
马尔可夫假设•当前状态出现的概率仅同过去有限的历史状态有关，而与其他状态无关。具体到分词任务，就是文本中第i个词出现的概率仅仅依赖于它前面的i-1个词，而与其他词无关。
输出独立性假设•当前状态的输出仅仅取决于当前状态本身，而与其他状态无关。

生成式分词
学习
素材
句子
切分
结果
分词
知识库
产生式
学习算法
产生式
切分算法
分词
词典

生成式分词
分词过程实例第一步：全切分

生成式分词
第二步：Viterbi动态规划，找到贯穿句子的路径并计算
每条路径的概率
P1=P(说|他)*P (的|说)*P(确实|的)*P(在理|确实)*P($End|在理)P2=P(说|他)*P (的确|说)*P(实在|的确)*P(理|实在)*P($End|理)
第三步：选择概率最大的路径为切分结果

生成式分词
优点
在训练语料规模足够大和覆盖领域足够多的情况下，可以获得较
高的切分正确率（>=95%）
•不足
需要很大的训练语料
新词识别能力弱
解码速度相对较慢

统计分词
生成式统计分词
判别式统计分词

判别式分词
原理
在有限样本条件下建立对于预测结果的判别函数，直接对预测结果进行
判别，建模无需任何假设。
由字构词的分词理念，将分词问题转化为判别式分类问题
典型算法
MaxentSVMCRFPerceptron
优势
能充分利用各种来源的知识
需要较少的训练语料
解码速度更快
新词识别性能好

判别式分词
由字构词
把分词问题转化为确定句中每个字在词中位置问题
每个字在词中可能的位置可以分为以下三种
词首B（日本占领了东三省）
词中M（游泳比赛菲尔普斯独占鳌头）
词尾E（中国队抢占了风头）
分词结果形式化分词结果：毛/B新/M年/E2/B0/M0/M0/M年/E毕/B业/E/于/B东/B北
/M大/M学/E还原：毛新年/2000年/毕业/于/东北大学

判别式分词
学习
素材
句子
切分
结果
分词
知识库
判别式
学习算法
判别式
学习算法

判别式分词
特征所涉及的语言学知识列表字的上下文知识形态词知识：处理重叠词、离合词、前后缀仿词知识：2000年成语/惯用语知识普通词词典知识歧义知识新词知识/用户词典新词的全局化知识

判别式分词
优点
理论基础扎实
解码速度快
分词精度高
新词识别能力强
所需学习素材少
弱点
训练速度慢
需要高配置的机器训练

到底应该使用哪种算法呢？
•到底哪种分词算法的
准确度更高，目前并
无定论。对于任何一
个成熟的分词系统来
说，不可能单独依靠
某一种算法来实现，
都需要综合不同的算
法。

31第三节：中文分词
中文分词概念理解
中文分词常用算法
中文分词的难点及应用领域

中文分词难点
分词难点
歧义无处不在
交叉歧义（多种切分交织在一起）内塔内亚胡说的
/
确实
/
在理
组合歧义（不同情况下切分不同）这个人/
手
上有痣我们公司人手
真歧义（几种切分都可以）乒乓球拍
/
卖
/
完了乒乓球/拍卖/
完了

中文分词难点（续）
分词难点新词层出不穷人名、地名、机构名奥巴马表哥房叔
网名你是我的谁旺仔小馒头
公司名、产品名摩托罗拉谷歌爱国者腾讯网易新浪诺基亚
C5  尼康D700

中文分词难点（续）
分词难点
普通词与新词互用
高明表演真好（演员）/他的表演很高明
汪洋到深圳检查工作/洞庭湖一片汪洋
普通词与新词交织在一起
克林顿对内
塔尼亚胡说
胡锦涛听取龚学平等
同志的汇报

中文分词难点（续）
分词难点（需要重新处理）
需求多种多样
切分速度：搜索引擎VS单机版语音合成
结果呈现：切分粒度要求不同：机器翻译VS搜索引擎分词重点要求不同：语音合成VS搜索引擎唯一结果VS多结果：语音合成VS搜索引擎新词敏感度不同：语音合成VS搜索引擎
处理对象：书面文本(规范/非规范)VS口语文本
硬件平台：嵌入式VS单机版VS服务器版

常见分词系统
•ICTCLAS
–Institute of Computing Technology, Chinese Lexical Analysis System
•由中国科学院计算技术研究所开发
•主要功能有
•自动分词
•词性标注

常见分词系统（续）
•斯坦福分词系统•斯坦福分词系统是一个开源的软件，它基于CRF（Condition Random 
Field，条件随机场）机器学习理论。•该系统提供了了两个分词数据模型，–一个是基于宾州中文树库，–另外一个是基于北京大学为sighan第二届中文分词竞赛提供的数据•使用形式如下：–segment ctb|pkfilename encoding–参数说明如下：–ctb: 宾州中文树库。–pk: 北京大学语料库。–filename: 待分词的文件名。–encoding: 待分词文件的编码，可以是UTF-8, GB18030等
java
所支持的编码。

中文分词的应用领域
搜索
引擎
自动
摘要
机器
翻译
文本
分类
语音
合成
语义
分析

第四节：中文新词识别概述
新词的概念
新词识别的任务
新词识别的发展过程
新词识别的方法
新词识别目前存在的问题
新词识别的基础知识

4新词的定义
•词典参照的角度
–现代汉语基本词汇所没有的词语
•新形式
•新意义
•新用法
•时间参照角度
–在某一时间段内或自某一时间点以来首次出现的具有新
词形、新词义或者新用法的词汇
–随着互联网不断发展，新词大量涌现

5未登录词与新词
•未登录词：未在当前所用词典中出现的词
•新词：随着时代的发展而新出现或旧词新用的词
•多数研究者对这两个概念不加区别
•中文信息处理领域新词识别
–一般把新词视为未登录词来进行处理

•对未登录词的处理在实用分词系统中举足轻重
–林徽因
此离开了这
–他们来自中国科学院软件研究所
等有关单位，前来参加中石油大庆石化公司
与软件研究所
的第二期合作洽谈与签约。
6

7新词的分类
•按照来源分类
–命名实体•“中国人寿”, “李强”,“安徽”–缩略语•“非典”–方言词•“埋单”–新造词•“超女”，“山寨”，“美眉”–专业术语•“禽流感”–音译词•“克隆”–字母词•“MTV”–词义及用法发生变化的旧有词语•“下课”、“充电”

新词识别的任务
•候选新词的提取以及垃圾字串的过滤
•新词的词性猜测
8

新词识别的发展过程（一）
•最早的一篇文章是1990 年汪华峰的《汉语自然语言理解中
词切分中新词问题初探》
–基于统计的方法，只考虑了词频一个特征
•在之后的十年研究成果较少
•2002 年郑家恒等人的《基于构词法的网络新词自动识别初
探》
–采用了规则的方法
–对新词的词长、构词规则进行了总结，依靠语言学规则
进行新词识别，取得了较好的效果
9

新词识别的发展过程（二）
•近十几年研究较多
–统计方法或统计、规则方法相结合逐渐成为了主流方法
•徐远方使用支持向量机（SVM）将新词识别看做一个分类问题利用词特征进行识别，
–正确率达到61.78%，召回率73.68%，F 值为67.20% 。
•林自芳基于词内部模式的新词识别方法
–准确率为65.7%，召回率为67.3%，F 值为66.5% 。
•崔世起根据新词构词模式、词性规则和独立词概率方法进行新词识别
–准确率达到95%以上。
•吴悦等采用一种基于二元背景模型的新词发现方法，
–准确率为57%，召回率为59%，F 值为58% 。
10

•李钝等采用
N-gram 算法和局部匹配预测算法（PPM）识别新词
–准确率为92%，召回率为90.8%，F 值为91.3% 。
•陈飞等基于条件随机场的方法识别新词
–准确率、召回率和F 值都达到了90%以上。
•邹纲等人主要采用时间特征和规则进行新词识别
–准确率在30%以上，召回率可达到90%以上。
•丁建立等采用免疫遗传算法进行新词识别
–准确率为87.6%，召回率为79.5%，F 值为83.4% 。
–从实验结果来看，
N-gram 算法、局部匹配预测算法（PPM）
、条件随机场算法和免疫遗传算法对新词识别效果较好，准确
率、召回率和F 值都比较高。
11

新词识别的方法
•基于规则的方法
•基于统计的方法
•规则与统计相结合的方法
12

基于规则的方法（一）
•利用语言学知识，总结新词的构词特点建立规则库，利用规
则库筛选新词
•优点
–准确率高
•缺点
–构建规则库工作量大、成本高
–规则不能概括所有的语言现象•对于不符合规则的新词会造成遗漏，且规则过多规则之间容易相互冲突
–规则库的更新困难•新词产生的速度快、组词灵活，构建的规则库难以适应新词产生的速度
–移植性差•规则方法常与特定领域相关
13

基于规则的方法（二）
•新词词性规则
–新词主要集中在名词、动词、形容词这三类实词上
–名词所占比例最高，
–虚词一般不构成新词
14

基于统计的方法（一）
•统计方法主要以大规模语料库作为训练语料，根据新词的特点统计各种有效数据来识别新词。逐渐成为主流方法。
•优点：
–统计方法不依赖规则,不限定领域,移植性好。
•缺点
–统计方法的计算量大
–含形成大量垃圾串，垃圾串的过滤是统计方法的难点。
15

新词识别的统计特征
•新词识别的统计特征：
–字或词的频数和出现文数
–词内部概率
–时间特征
–邻接类别
16

字或词的频数和出现文数
•满足作为词的特征
•需要具备一定的使用度和通用度，即新词要满足一定的频次和出现文数要求
–新词的一个基本判定条件，多数学者会使用
–新词的频次往往设为最小值2。
•此方法可用‘出现度’（Dp）来作为挖掘新词的衡量标准
•计算公式为：
•D
p= 
Freq´p +Texts ´q
–其中p、q 为权值，根据处理的文本信息总量不同调整。
–频数（Freq）
–出现文数(Texts)
–‘出现度’（Dp）
17

时间特征
•前景语料背景语料
18
P 
fore(b i)是b i在前景语料中的概率
P back(b i)是b i在背景语料中的概率

词内部概率
•N(W)是词W 在文本中总的出现次数
•N（W in-another
-word ）是词W 在文本中作为某目标
词语组块的一部分出现的次数
19

邻接类别
•新词作为词，内部要稳定，上下文要灵活
•上下文邻接（左邻接、右邻接）集合
–集合元素越多，说明词的上下文语境越灵活，越可
能是一个新词
20

规则和统计相结合的方法
•规则方法和统计方法各有不足，将两种方法相结合以提高识别效果。
–实践中采用统计方法为主辅之以规则方法过滤，对规则的深入研究和运用仍
然较少。
–采用统计和规则相结合的方法来识别新词的文献
•王琳琳.规则与统计相结合的中文新词识别研究[J].嘉兴学院学报.2014 年11 月
•程涛，施水才，张玉杰，吕学强.基于大规模语料库的新闻领域新词挖掘[C].第三
届全国信息检索与内容安全学术会议.2007 年11 月
•张苏，梁颖红，牛丽.基于术语抽取技术的新闻新词发现方法研究[J].苏州市职业
大学学报.2014 年9 月
21

新词识别的基础知识
22

正确率、召回率、F 值
•正确率= 提取出的正确新词数/ 提取出的新词数
•召回率= 提取出的正确新词数/ 样本中的新词数
–两者取值在0和1之间，数值越接近1，正确率或召回
率就越高。
•F值= 正确率* 召回率* 2 / (正确率+ 召回率) 
–F 值即为正确率和召回率的调和平均值
23

新词识别研究的主要技术方法
•基于支持向量机（SVM）
•基于最大熵模型（ME）或条件随机场模型（CRF）
•N-gram
•基于隐马尔科夫模型（HMM）
•基于决策树（DT）
•监督方法与非监督方法
24

支持向量机
25

存在的问题
•新词识别方法具有一定局限性
•识别效果有待提高
•新词定义不统一，人工判定新词的具有主观性
•新词产生时间的模糊性，
•分词后识别方法中的分词错误
•垃圾串过滤的复杂性
•少数民族语的新词识别研究几乎没有
•多语种的新词识别研究成果非常少

研讨一：linux下键盘输入法调研
2

Fcitx框架
•Fcitx
–Fcitx是一个以GPL方式发布的、基于XIM的简体中文输入法集合，
包括拼音、区位和码表输入法。
•XIM
–XIM(X Input Method)是建立在I18N(国际化Intemationization)与Locale(本地化)上的输入法协议，
–目地是为了不更改原始代码本身就可适应各语系

Fcitx
•XIM体系结构
–在X -WINDOW 下XIM 主要有两种典型的系结构:•Client/Servers 模型•Library 模型
•Client/Servers 模型
–IM服务器是一个独立的进程，由它来处理输入、预编辑、转换和确认。
–IM库存在于应用程序中，就象IM服务器的一个客户，它只是简单的从IM服务器接收确认字符串。
Fcitx框架

Fcitx
•Library 模型
–所有的输入都由应用程序中的IM库来处理。事件处理在IM库中就被关闭了，所以就不再需要一个独立的IM服务器。
•有复杂的预编辑语言采用Client/Server模型
–亚洲语言，如中文
•只有一些死键或组合键的语言采用Library模型
–欧洲语言，如英文
Fcitx框架

Fcitx
•Client/Server模型
–在XIM 模型中, 客户端程序Client 即需要输入的应用程序，
是
通过XIM 协议来连接IM 服务器之后最终实现XIM 输入。使
用XIM 协议的输入法程序称之为XIM Server 。IM 子系统则主
要负责文字的查找和文字的组合。它们之间是通过XIM 协议
实现通讯。
Fcitx框架

Fcitx
•Fcitx包括以下模块:
–主模块•程序的入口，以及错误处理
–XIM接口•调用ImdKit
–用户界面•用户输入界面以及程序界面
–程序配置模块•读取/保存程序配置文件, 并设置相关参数
–输入法入口模块•调用相应的输入模块处理公共键盘事件等
Fcitx框架

Fcitx
•Fcitx包括以下模块
–标点符号处理模块•处理用户输入的标点符号
–区位输入模块•提供简单的区位输入功能
–拼音模块•提供智能拼音( 全拼、简拼、双拼) 及特殊符号输入功能
–码表输入模块•提供基于码表的输入功能，五笔/二笔/仓领等输入法都属于这类输入法
Fcitx框架

Scim框架
•Scim
–Scim(Smart Common lnputMethod Platform)是由苏哲领导的简体中文输入法框架
•对比XIM 
–Scim使用了较高级的程序库，所以拥有更容易使用的接口，而且可以与XIM并存。
•Scim优点
–Scim架构设计精良, 具有很好的扩充性和灵活性, 不仅提供了友好的用户界面, 支持符合POSIX 操作系统标准的输入特点, 而且更易于开发新的输入法。
–Scim项目可支持大约三十多种语言的输入, 如中文的简体繁体、日文
、韩文等(其中一些需要其自己的库)

Scim
•Scim具有如下特点：
–完全面向对象的设计，并用C++实现
–高度模块化
–非常灵活的设计，支持动态加载不同的输入法，支持C/S模型运行
–简单的编程接口
–对Unicode提供全面支持
Scim框架

Scim
•Scim具有如下特点：
–提供了一些非常好用的工具函数，可以大大加快开发进度
–提供了功能丰富的GUI panel
–提供了统一的配置框架
–很方便的集成现存的输入法
–不但支持传统的键盘输入法，也支持手写识别等新式输入法
Scim框架

Scim
•Scim的组成部件
–配置模块(Config)
–输入法前端模块(FrontEnd)
–输入法引擎模块(IMEngine)
–进程间通信模块(IPC)
–输入法Panel
–输入法Helper
Scim框架

Scim
•SCIM中的前端模块前端有不同的实现，这些实现都遵循FrontEndBase接口规范，提供了两个默认的实现：X11FrontEnd
和SocketFrontEnd。
–X11FrontEnd 是基于XIM 实现、为了和XIM兼容而设的
–SocketFrontEnd,它定义了一套自己的通信协议，的通讯采用的是signal—slot技术
Scim框架

Ibus
•Ibus
–Ibus（intelligent input bus）是下一代输入法框架（或者说“平台”
），是在类unix操作系统中是一个为了多语言输入的输入法框架，之所以叫做“Ibus”原因在于它是一个总线型的架构。
•Ibus 项目现托管于Google Code -https://code.google.com/p/ibus/
此项目包含了世界多数语言的文字输入需求——由世界多个国家开发者维护。
Ibus框架

Ibus框架
•Ibus架构

Ibus
•Ibus是基于c/s的架构
–他有一个ibus-daemon的后台进程，管理所有的客户端
–所有的engines、panel、config modules和IM(Input Method) clients都是ibus-daemon的客户端
–Ibus是基于dbus ipc协议的
Ibus框架

Ibus
•Ibus的优势
–Ibus使用dbusrpc进行通信，客户端可以使用任何一种语言去和Ibus交互
；
–ibus-daemon, engines, clients&UI都运行在独立的进程中。
Ibus框架

Ibus
•相比Scim，Ibus改善的地方在于：
–Scim使用C++编写，并用了STL（标准模板库），具有弱符号冲突问题，而ibus的最初版用python，后改用C语言。
–可以为任何支持dbus绑定的语言编写客户端和引擎。
–Ibus只加载所需要的引擎，提高了启动时间，减少了内存消耗。
–Scim加载所有引擎作为dl-modules，因此加载任何引擎出错时都可能导致scim出故障。而ibus是分开处理的，一个出错，其他正常运行不受影响。
Ibus框架

对研讨问题1的回答
•从用户界面、易用性、支持输入法种类、拼音/五笔输入法功能支持对比等方面比较Fcitx、Scim、Ibus等键盘输入法的差异和优缺点？
–Fcitx：•候选词横排，与window下用户体验输入法一致，易用性较好•支持中文输入，支持种类较少•默认支持智能拼音、五笔输入和区位
19

对研讨问题1的回答
–Scim：•候选词竖排•支持中文输入，支持种类较少•拼音输入法：输入短语时，每次只显示最后单个词的拼音•输入词组时，候选词组较少
20

对研讨问题1的回答
–Ibus：•候选词竖排•拼音输入法：输入词组时，拼音串显示在文本区域•输入词组时，候选词组较少•支持世界多数语言，支持语言种类最多
21

对研讨问题1的回答
•10种输入法
–Xsim、Fcitx、Chinput、Xcin、Scim、Fitx、IBus、Rime、搜狗输入法
for linux、小小输入法

•全称为X Simple Input Method，作者是楚狂
•支持简拼、五笔的中文输入
•优点
–界面美观、光标跟随做得很好、可定制性较强
•缺点
–系统依赖性较强，依赖相关软件和版本•相关软件不全，甚至版本不同可能导致安装失败
–常见词组似乎不太符合惯例•一些高频的词组要翻几次才能找到
对研讨问题1的回答

•小企鹅输入法，作者是Yuking
•默认支持智能拼音、五笔、区位输入
•优点
–小巧易用、配置简单、兼容性好
•缺点
–只能支持中文输入而且种类较少
–基于XIM，若崩溃会导致用户数据丢失
对研讨问题1的回答

•Chinput是Linux 图形界面下较早的中文输入法，支持XIM 协议和早期自定义的Chinput协议。
•90年代中期开发，2001年3月改为minichinput
•优点
–支持XIM的四种输入风格，可自动切换。
–有较好的图形操作接口、也有很多可供配置的选项，如字体、颜色等。
•缺点
–界面和易用性上创新不够、不能进行中英文的快速切换。
对研讨问题1的回答

对研讨问题1的回答
•台湾同胞的作品，支持BIG5、BIG5HKSCS、GB2312 以及UTF-8 
等多种编码方式
•优点
–最佳的繁体中文输入，默认使用空格键翻页
•缺点
–不支持拼音词组，很多选项的配置也比较麻烦，不符合用户的使用习惯

•Scim全称Smart Common Input Method，苏哲领导开发的新一代输入法框架
–支持中日韩等多种语言
•优点
–架构设计精良、结构清晰，具有很好的扩充性和灵活性
–使用C++编写而成，具有高度的模块化
•缺点
–预先加载所有引擎，因此加载任何引擎出错时都可能导致故障
对研讨问题1的回答

•全名Fun Input Toy for Linux
•Fitx的姐妹版Fun Input Toy, 是Mac OS X下最流行的输入法之一
•Fitx是建立在scim和scim-python上的输入法
•特点：
–同时支持拼音，双拼，全双混拼；五笔，五笔拼音混合输入
–智能短句
–自动记忆拼音词组、自动词频调整
–海量词库，拼音词条37万条，五笔词条8万条
–支持五笔自定义词组
对研讨问题1的回答

•Ibus（intelligent input bus）是下一代输入法框架（或者说“平台”）
–是Linux和类UNIX操作系统下的以GPL协议分发源代码的开源免费多语言输入法框架。
–命名“Ibus”原因在于采用总线式（Bus）的架构。
•Ibus项目现托管于Google Code -https://code.google.com/p/ibus/
，此项目包含了世界多数语言的文字输入需求，由世界多个国家开发者维护。
对研讨问题1的回答

•中州韵输入法引擎（Rime Input Method Engine），又称Rime输入法，
作者是佛振
•项目网站设在GoogleCode，代码托管在GitHub
•基于同一个核心架构，该输入法分为三个发行
–Linux发行版中州韵（英语：ibus-rime）
–Windows发行版小狼毫（英语：Weasel）
–MacOS发行版鼠须管（英语：Squirrel）
•特点
–扩展性较强，内置多种输入方案
–不易于普通用户上手
对研讨问题1的回答

•搜狗输入法在2014年4月发布了Linux版本
–使用Fcitx框架
–开源Qimpanel面板
–搜狗输入法引擎
–具有智能拼音、自动匹配、多样化皮肤支持等功能
对研讨问题1的回答

对研讨问题2的回答
32
输入功能功能点功能详述Fcitx-sunpinyinFcitx-pinyinFcitx-googlepinyinLinux搜狗输入法Fcitx
—libPinyin输入法
输入法常用设置设置翻页常用翻页键除pageDown和pageUp外有三组“，。”；“[]”;“-=”
，
可通过设置功能配置；支持2组翻页按键,不支持配置翻页键
；
“-=”,“，。”支持2组翻页按键,不支持配置翻页键；“-=”,“，。”不支持配置翻页键；；支持2组翻页按键,不支持配置翻页键；“-=”,“，。”,不支持配置翻页键
；
支持2组翻页“-=”,“，。”支持配置翻页键
；
支持2组翻页按键,不支持配置翻页键；“-=”,“，。”不支持配置翻页键
；
设置候选词个数设置选词候选个数；不能通过用户配置候选词的个数；不能通过用户配置候选词的个数；不能通过用户配置候选词的个数；能通过用户配置候选词的个数；不能通过用户配置候选词个数
设置输入法外观输入法皮肤设置能配置系统给定的皮肤
；
能配置系统给定的皮肤；能配置系统给定的皮肤；能配置系统给定的皮肤；能配置系统给定的皮肤；

输入功能功能点功能详述Fcitx-sunpinyinFcitx-pinyinFcitx-googlepinyinLinux搜狗输入法Fcitx
—libPinyin输入法
基本输入功能简拼声母简拼和声母的首字母简拼;简拼支持模糊音；支持支持支持支持支持
模糊音支持易混淆音节输入支持支持，不可增加，可减少设置模糊音，不支持不支持支持，不可增加，可减少设置模糊音
上下文调序根据输入法的上下文，调整候选词序；不支持不支持不支持通过云输入给出相关的短语，不支持
云输入通过互联网来计算输入内容不支持不支持不支持支持不支持拼写纠错不符合拼音拼写规则的支持支持支持支持支持动态调频根据用户输入内容，调整频率，常用词先出现在候选列表支持支持支持支持支持
动态组词一次输入一整句话，而不是单词输入不支持不支持不支持支持，通过云输入给出相关的短语，不支持
联想输入根据输入的多个词组扩展输入，形成候选词不支持不支持不支持支持，可配置不支持
智能数字标点输入数字后的标点，根据需要改成半角；支持支持不支持支持支持
英文输入补全输入英文时，能提示英文单词支持支持支持支持支持
双拼输入多种双拼方案输入支持支持不支持不支持支持英文网站自动转换输入网站相关字母组合时，提供相关的英文输入形式输入www自动转换为英文，但是不能完整输入网址输入www自动转换为英文，但是不能完整输入网址输入www自动转换为英文，但是不能完整输入网址支持输入www自动转换为英文，但是不能完整输入网址
简繁转换简体字和繁体字输入支持支持支持支持支持
33

34
输入功能功能点功能详述Fcitx-sunpinyinFcitx-pinyinFcitx-googlepinyinLinux搜狗输入法Fcitx
—libPinyin输入法
智能输入功能V模式输入输入v后再输入数字等字符，得到经过计算的输入结果不支持不支持；不支持；不支持不支持
U
模式输入输入U字母后，可以拆字或者按笔画输入不支持不支持不支持；支持笔画输入。不支持拆部首输入。不支持
智能人名输入输入人名后，可以进入人名模式
，
系统根据计算出人名常用字；支持支持不支持不支持
日期时间输入输入rq，xq等候选项中有当前日期
；
不支持不支持不支持支持不支持
拆分输入直接拆分生僻汉字输入不支持不支持不支持不支持不支持笔画筛选候选项较长的拼音时，输入tab键和笔画顺序，快速选字不支持不支持不支持不支持不支持
拆字辅助码候选项较长的拼音时，输入tab键和拆字结果来快速选字不支持不支持不支持不支持不支持
自定义短语自定义不属于拼音范畴的常用短语，提高输入效率不支持不支持不支持不支持不支持
搜索个人文档建立词库搜索本地电脑上的文档，浏览历史等个人信息，建立个人词库，提高输入效率不支持不支持不支持不支持不支持

对研讨问题2的回答
功能点应用场景依赖数据插件形式拆字及笔画输入功能在拼音输入法中增加拆字或者笔画输入功能，如输入引导符+“huohuohuo”，能打出“焱”字，以便在不确定读音的情况下用拼音输入法输入汉字；汉字拆字数据；采用module形式，可应用于所有fcitx输入法；安装该插件后，所有fcitx输入法均能支持拆字输入；
增加v模式计算功能输入v后再输入数字等字符，得到经过计算的输入结果数字转中文算法；采用module形式，可应用于所有fcitx输入法；
网址自动转化工具输入网站名称如“新浪
”
给出www.sina.com
的候选项；主流网站相关数据；
输入法码表更新工具搜集新词术语，更新码表词库以适应用户输入需求；新词术语收集算法；更新新词后，依赖fcitx拼音码表的输入法能使用最新码表


研讨三：中文分词调研
2

Paoding
•概述
–主页：https://code.google.com/p/paoding/
–Paoding'sKnives中文分词具有极高效率和高扩展性。引入隐喻，采用完全的面向对象设计，构思先进。
–高效率：在PIII 1G
内存个人机器上，1秒可准确分词100万汉字。
–采用基于不限制个数的词典文件对文章进行有效切分，使能够将对词汇分类定义。
–能够对未知的词汇进行合理解析
–使用Java 开发编译、支持Lucene3.0
–2010年1月后停止更新
•算法
–最小二分法•最多的匹配词典中的词
–最大切分法•使每一句中切出的词数最小
3

Paoding
•接口
–Java API
•使用实例–Analyzer analyzer= new PaodingAnalyzer(properties); //生成analyzer实例–TokenStreamstream = analyzer.tokenStream("", reader); //取得Token流–stream.reset();//重置到流的开始位置–TermAttributetermAtt= (TermAttribute) stream.addAttribute(TermAttribute.class); OffsetAttribute
offAtt= (OffsetAttribute) stream.addAttribute(OffsetAttribute.class);//添加工具类–//循环打印所有分词及其位置–while (stream.incrementToken()) {–System.out.println(termAtt.term() + " " + offAtt.startOffset() + " " + offAtt.endOffset());–}
4

Ikanalyer
•概述
–IK Analyzer 是一个开源的，基于
java
语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了4个大版本。
–最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。从3.0版本开始，IK发展为面向Java
的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。
–Core2 i7 3.4G
双核，4G
内存，window 7 64位，Sun JDK 1.6_29 64位普通pc环境测试，IK2012具有160万字/
秒（3000KB/S）的高速处理能力
–采用了多子处理器分析模式，支持：英文字母、数字、中文词汇等分词处理，兼容韩文、日文字符
–基于Java
开发
•算法
–正向迭代最细粒度切分算法•公路局| 公路| 路局| 正在| 治理| 理解| 解放| 放大| 大道| 道路| 路面| 面积| 积水| 问题
–智能切分算法•公路局| 正在| 治理| 解放| 大道| 路面| 积水| 问题
5

Ikanalyer
•接口
–以Jar包的形式提供Java API
•使用实例//构建IK分词器，使用smart分词模式Analyzer analyzer= new IKAnalyzer(true);//获取Lucene的TokenStream对象TokenStreamts= null;ts= analyzer.tokenStream("myfield", new StringReader("这是一个中文分词的例子，你可以直接运行它！IKAnalyer
can analysis englishtext too"));//获取词元位置属性OffsetAttributeoffset = ts.addAttribute(OffsetAttribute.class); //获取词元文本属性CharTermAttributeterm = ts.addAttribute(CharTermAttribute.class);//获取词元文本属性TypeAttributetype = ts.addAttribute(TypeAttribute.class);//重置TokenStream（重置StringReader）ts.reset(); //迭代获取分词结果while (ts.incrementToken()) {System.out.println(offset.startOffset() + " -" + offset.endOffset() + " : " + term.toString() + " | " + type.type());}//关闭TokenStream（关闭StringReader）ts.end();   // Perform end-of
-stream operations, e.g. set the final offset.6

Mmseg4j
•概述
–基于Mmseg算法实现的中文分词器，并实现lucene的analyzer 和solr
的TokenizerFactory以方便在Lucene和Solr中使用。
–MMSeg算法有两种分词方法：Simple和Complex，都是基于正向最大匹配。Complex加了四个规则过虑。官方说：词语的正确识别率达到了98.41%。mmseg4j已经实现了这两种分词算法。
–目前complex 1200kb/s左右, simple 1900kb/s左右
–基于Java
开发
•算法
–正向最大匹配•简单最大匹配算法–假设C1,C2,….代表一个字符串中的汉字。首先搜索词典，看_C1_是否为一个单个汉字组成的单词，然后搜索_C1C2_来看是否为一个两个汉字组成的单词，以下类推。直至找到字典中最长的匹配。最可能的单词就是最长的匹配。•复杂最大匹配算法–最可能的分词方案是三个单词。从一个字符串的头部开始，寻找分词的方案。如果存在有歧义的分词（例如，_C1_是一个单词，但是_C1C2_也是一个单词，等等），然后我们向前再看两个单词去寻找所有可能的以_C1_ 或者_C1C2_ 开头的三词chunks 。
7

Mmseg4j
•接口
–JavaAPI
•使用实例
–Java
命令方式•java -cp.;mmseg4j-1.6.jar com.chenlb.mmseg4j.example.Simple sentence
–源码：String txt = "";txt = "京华时报1月23日报道昨天，受一股来自中西伯利亚的强冷空气影响，本市出现大风降温天气，白天最高气温只有零下7摄氏度，同时伴有6到7级的偏北风。";Dictionary dic= Dictionary.getInstance();Segseg= null;//seg= new SimpleSeg(dic);seg= new ComplexSeg(dic); MMSegmmSeg= new MMSeg(new StringReader(txt), seg);Word word= null;System.out.println();while((word=mmSeg.next())!=null) {System.out.print(word.getString()+" -> "+word.getStartOffset());//offset += word.length;System.out.println(", "+word.getEndOffset()+", "+word.getType());} }
8

Jieba
•概述
–基于python实现的中文分词，目标是做最好的python中文分词软件；
–特点：•支持三种分词模式：–精确模式，试图将句子最精确地切开，适合文本分析；–全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义
；–搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。•支持繁体分词•支持自定义词典
•算法
–基于前缀词典实现高效的词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图(DAG)
–采用了动态规划查找最大概率路径, 找出基于词频的最大切分组合
–对于未登录词，采用了基于汉字成词能力的HMM 模型，使用了Viterbi 
算法
9

Jieba
•接口
–Pythonpackage：import 
jieba
–命令行
•使用实例
–命令行：•python -m 
jiebanews.txt > cut_result.txt
–源码：# encoding=utf
-8import 
jiebaseg_list= 
jieba.cut("我来到北京清华大学", cut_all=True)print("Full Mode: " + "/ ".join(seg_list))  # 全模式seg_list= 
jieba.cut("我来到北京清华大学", cut_all=False)print("Default Mode: " + "/ ".join(seg_list))  # 精确模式seg_list= 
jieba.cut("他来到了网易杭研大厦")  # 默认是精确模式print(", ".join(seg_list))seg_list= 
jieba.cut_for_search("小明硕士毕业于中国科学院计算所，后在日本京都大学深造")  # 搜索引擎模式print(", ".join(seg_list))10

ICTCLAS
•概述
–NLPIR
汉语分词系统(又名ICTCLAS2013),主要功能包括中文分词；词性标注；命名实体识别；用户词典功能；
–支持GBK编码、UTF8编码、BIG5编码。
–新增微博分词、新词发现与关键词提取；
–基于C/C++开发
•算法
–基于层叠形马尔可夫模型（CHMM）•增加了分词的准确性•保证分词的效率
11

ICTCLAS
•接口
–C++接口
–JNI接口
java 调用c/
c++
–C#接口
•使用实例int_tmain(intargc, _TCHAR* argv[])  {  if(!
NLPIR_Init())   {  printf
("Initfails\n");  return -1;  }  constchar *participle_result;  constchar *sentence = "[整租出租]宣武门西大街4号楼二居整租[整套出租]媒体村天居园大两居[整套出租]媒体村天居园大两居";  cout<< "===============
NLPIR_ParagraphProcess==================" << endl;  participle_result= 
NLPIR_ParagraphProcess(sentence,1);  cout<< participle_result<< endl;  cout<< "=================================" << endl;  }12

StandfordSegmenter
•概述
–基于Java
实现的中文分词软件，该软件不只是针对中文还可以实现对阿拉伯文的分词。
–包含多语言分词、命令实体识别、新词发现等功能。
–基于JDK1.8+
•算法：
–基于CRFs实现•CRF把分词当做字的词位分类问题–词首，常用B表示–词中，常用M表示–词尾，常用E表示–单子词，常用S表示
13

StandfordSegmenter
•接口
–命令行
–Java API
•使用实例
–命令行•segmenter.bat ctbinput.txt gb18030 0 >output.txt
–JavaAPI
14

中文分词器分词效果评估对比
15
JiebaMMSeg4jIKAnalyzerStanfordPaoding
分词速度867.4031 字符/毫秒1685.1461 字符/毫秒334.3131 字符/毫秒1338.9246 字符/毫秒13.723294 字符/毫秒
行数完美率50.84%34.27%18.87%55.45%511.6%
字数完美率41.54% 25.2%10.9347.27%5.92% 
例子我爱楚离陌我爱楚离陌我爱楚离陌我爱楚离陌-

小结
•分词效果
–基于统计的分词目前取得的效果要高于基于规则的分词
•分词方法
–基于规则+基于统计的方法
•分词速度
–基于统计的分词速度并不比基于规则的分词慢
16

基于规则的分词方法
•引起分词错误的主因
–未登录词•“青岛大虾”、“然并卵”、“小鲜肉”
–组合型歧义•某些汉字串，它本身是词，切开来也是词，这就造成了组合型歧义•“就是”、“业余足球爱好者”
–交集型歧义•一个汉字串中包含ABC三个子串，AB和BC都是词，到底应该切分为A/BC
还是AB/C•“白天鹅”、“从小学”
17

分词方法对比
18
规则分词理解分词统计分词
歧义识别差强强
新词识别差强强
词典需要不需要不需要
语料库不需要不需要需要
规则库不需要需要不需要
算法复杂度低高中
分词准确率低高中
技术成熟度成熟不成熟成熟

英文是否需要分词
•英文需要分词，但是与中文分词不同
–英文单词之间有空格进行隔开
–英文有词组，如“stanfordsegmentor”、“CarnegieMellonUniversity”
19

微博分词面临的新问题
•新专有名词
–用户名、地名、品牌名、电影名…..
•微博新词
–网络流行语、字母简写（HR
）、简写…..
•不规范表达
–口语化、方言、符号语


研讨四：
新词识别基础内容和技术调研
2

新词的定义
新词的定义概念
概念
词典参照的角度
F现代汉语基本词汇所没有的词语（新形式、新意义、新用法）
时间参照角度
F在某一时间段内或自某一时间点以来首次出现的具有新词形、
新词义或者新用法的词汇

新词的分类及各种分类的
新词的分类及各种分类的分别
分别举例
举例
命名实体（包括人名、地名、商品名、公司字号、机构
名等）、缩略语、方言词、新造词、专业术语、音译词
、字母词、词义及用法发生变化的旧有词
命名实体：包括人名、地名、商品名、公司字号、机构
名等，如“中国人寿”
, “李强”,“安徽”
缩略语：“非典”、“计生委”
方言词：“埋单”、“靓”
新造词：“超女”
专业术语：“禽流感”
音译词：“克隆”
字母词：“MTV
”、“WTO”
词义及用法发生变化的旧有词语：“下课”、“充电”

新词发现的主要
新词发现的主要方法
方法
目前主要有:
基于规则的方法
基于统计的方法
规则和统计相结合的方法

基于规则的方法和基于统计的方法的主要思想
基于规则的方法和基于统计的方法的主要思想
基于规则的方法其主要思想是根据新词的构词特征或外型特
点建立规则库、专业词库或模式库，然后通过规则匹配发现
新词。
基于统计的方法，一般是利用统计策略提取出候选串，然后
再利用语言知识排除不是新词语的垃圾串。或者是计算相关
度，寻找相关度最大的字与字的组合。

新词识别的统计特征
新词识别的统计特征
字或词的频数和出现文数
词内部概率
时间特征
邻接类别

新词
新词识别评价标准
识别评价标准
正确率、召回率、F值
正确率= 提取出的正确新词数/ 提取出的新词数
召回率= 提取出的正确新词数/ 样本中的新词数
F两者取值在0和1之间，数值越接近1，正确率或召回率就越高。
F值= 正确率* 召回率* 2 / (正确率+ 召回率) 
FF 值即为正确率和召回率的调和平均值

新词识别研究的主要技术方法
新词识别研究的主要技术方法
基于支持向量机（SVM）
基于最大熵模型（ME）或条件随机场模型（CRF
）
N-gram
基于隐马尔科夫模型（HMM）
基于决策树（DT）
监督方法与非监督方法

基于最大熵模型（
基于最大熵模型（ME
ME）的方法的原理
）的方法的原理
熵是描述事物无序性的参数，熵越大则无序。
熵越大，事件越不确定。熵等于0，事件是确定的。
在无外力作用下，事物总是朝着最混乱的方向发展。在
已知条件下，熵最大的事物，最可能接近它的真实状态
。

隐马尔可夫模型
隐马尔可夫模型

隐马尔可夫模型解决的三个经典基本问题
隐马尔可夫模型解决的三个经典基本问题
评估问题
解码问题
学习问题

例子：病情转化
例子：病情转化

例子：词性标注
例子：词性标注

隐马尔可夫解决三大问题的算法
隐马尔可夫解决三大问题的算法
前后向算法
Viterbi算法
Baum Welch算法

HMM
HMM三大问题及对应
三大问题及对应算法


